# MNIST ANN Classifier with FGSM Adversarial Attacks

This repository contains code for training an Artificial Neural Network (ANN) classifier on the MNIST dataset and for crafting adversarial examples using the Fast Gradient Sign Method (FGSM) attack.

## Overview

The MNIST dataset is a collection of handwritten digits widely used for training and testing machine learning models. The goal of this project is to train an ANN classifier to accurately classify digits from 0 to 9 and to evaluate its robustness against adversarial attacks.

The Fast Gradient Sign Method (FGSM) is a popular technique for generating adversarial examples. Adversarial examples are crafted by perturbing input data in a way that maximizes the model's prediction error. These adversarial examples are designed to be imperceptible to humans but can cause the model to make incorrect predictions.
